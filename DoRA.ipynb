{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing DoRA: Weight-Decomposed Low-Rank Adaptation\n",
        "\n",
        "In this notebook we will be implementing the [Weight-Decomposed Low-Rank Adaptation (DoRA)](https://arxiv.org/abs/2402.09353) architecture, proposed by researchers as a technique that outperforms LoRA by a large margin.\n",
        "\n",
        "To follow along conceptually, you can refer to the [writeup](https://medium.com/p/f814ba519af4/edit) where we go over the theoretical concepts and the motivation behind LoRA and DoRA."
      ],
      "metadata": {
        "id": "HdGG50xVtQuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "cOqJyjurudcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "x7B7M4youSyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings and dataset"
      ],
      "metadata": {
        "id": "3UA8qJgSuvYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = datasets.MNIST(root='data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='data/',\n",
        "                               train=False,\n",
        "                               transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=False)\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break # Only print one, all will have the same dimensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khyuuPcpuhGi",
        "outputId": "2da7e37f-4db2-4b29-9de7-6da1bac48679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([64, 1, 28, 28])\n",
            "Image label dimensions: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXWETd0qvHTX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}