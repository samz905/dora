{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "PsFBcFL1l_OJ"
      },
      "source": [
        "# Implementing DoRA: Weight-Decomposed Low-Rank Adaptation\n",
        "\n",
        "This notebook implements and compares DoRA (Weight-Decomposed Low-Rank Adaptation) with LoRA across multiple architectures: MLP, CNN, and Attention models.\n",
        "\n",
        "Paper: [Weight-Decomposed Low-Rank Adaptation (DoRA)](https://arxiv.org/abs/2402.09353)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "Vv7NUL5bl_OK"
      },
      "source": [
        "## 1. Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxTTKs6Bl_OK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "aSmX9XGAl_OL"
      },
      "source": [
        "## 2. Settings and Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tf84Hnbl_OL",
        "outputId": "7a20d33c-64c1-409e-9b2e-2052098a4fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 479kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.77MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Training samples: 60000\n",
            "Test samples: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training settings\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "random_seed = 123\n",
        "learning_rate = 0.005\n",
        "num_epochs = 10\n",
        "\n",
        "# Dataset\n",
        "train_dataset = datasets.MNIST(root='data/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='data/', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "cVS4EzCgl_OM"
      },
      "source": [
        "## 3. MLP Model Definition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_mC8ZmYl_OM",
        "outputId": "500f2116-c40e-48c5-d66f-98ae1f958f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP architecture defined\n"
          ]
        }
      ],
      "source": [
        "# LoRA and DoRA Layer Implementations\n",
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
        "        super().__init__()\n",
        "        std_dev = 1 / torch.sqrt(torch.tensor(rank).float())\n",
        "        self.A = nn.Parameter(torch.randn(in_dim, rank) * std_dev)\n",
        "        self.B = nn.Parameter(torch.zeros(rank, out_dim))\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.alpha * (x @ self.A @ self.B)\n",
        "\n",
        "class LinearWithLoRA(nn.Module):\n",
        "    def __init__(self, linear, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.linear = linear\n",
        "        self.lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lora = self.lora.A @ self.lora.B\n",
        "        combined_weight = self.linear.weight + self.lora.alpha * lora.T\n",
        "        return F.linear(x, combined_weight, self.linear.bias)\n",
        "\n",
        "class LinearWithDoRA(nn.Module):\n",
        "    def __init__(self, linear, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.linear = linear\n",
        "        self.lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n",
        "        self.m = nn.Parameter(self.linear.weight.norm(p=2, dim=0, keepdim=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        lora = self.lora.A @ self.lora.B\n",
        "        numerator = self.linear.weight + self.lora.alpha * lora.T\n",
        "        denominator = numerator.norm(p=2, dim=0, keepdim=True)\n",
        "        directional_component = numerator / denominator\n",
        "        new_weight = self.m * directional_component\n",
        "        return F.linear(x, new_weight, self.linear.bias)\n",
        "\n",
        "# MLP Architecture\n",
        "class MultilayerPerceptron(nn.Module):\n",
        "    def __init__(self, num_features=784, num_hidden_1=128, num_hidden_2=256, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(num_features, num_hidden_1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_hidden_1, num_hidden_2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_hidden_2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        return self.layers(x)\n",
        "\n",
        "print(\"MLP architecture defined\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "Y2z4_j9Hl_ON"
      },
      "source": [
        "## 4. CNN Model Definition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhYbL-eel_ON",
        "outputId": "4cc5e5f7-f566-4410-99b2-e054a6cc9f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN architecture defined\n"
          ]
        }
      ],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # 28x28 -> 28x28\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 28x28 -> 14x14\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 14x14 -> 14x14\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 14x14 -> 7x7\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "print(\"CNN architecture defined\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "Atwhy4nnl_ON"
      },
      "source": [
        "## 5. Attention Model Definition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRy6geR-l_ON",
        "outputId": "c4b85f07-2664-4c9f-acc4-26325d14169d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention architecture defined\n"
          ]
        }
      ],
      "source": [
        "class SimpleAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.dim = dim\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.q_proj = nn.Linear(dim, dim)\n",
        "        self.k_proj = nn.Linear(dim, dim)\n",
        "        self.v_proj = nn.Linear(dim, dim)\n",
        "        self.out_proj = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "\n",
        "        q = self.q_proj(x).reshape(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.k_proj(x).reshape(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.v_proj(x).reshape(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "\n",
        "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.out_proj(out)\n",
        "\n",
        "class SimpleAttentionModel(nn.Module):\n",
        "    def __init__(self, patch_size=4, embed_dim=128, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_patches = (28 // patch_size) ** 2  # 49 patches for MNIST\n",
        "\n",
        "        self.patch_embed = nn.Linear(patch_size * patch_size, embed_dim)\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, self.num_patches, embed_dim))\n",
        "        self.attention = SimpleAttention(embed_dim, num_heads=1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "\n",
        "        # Convert to patches\n",
        "        x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
        "        x = x.contiguous().view(B, -1, self.patch_size * self.patch_size)\n",
        "\n",
        "        # Patch embedding + positional embedding\n",
        "        x = self.patch_embed(x) + self.pos_embed\n",
        "\n",
        "        # Attention and classification\n",
        "        x = self.attention(x)\n",
        "        x = x.mean(dim=1)  # Global average pooling\n",
        "        return self.classifier(x)\n",
        "\n",
        "print(\"Attention architecture defined\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "nu2plNcRl_ON"
      },
      "source": [
        "## 6. Initial Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3kk2TDul_OO"
      },
      "outputs": [],
      "source": [
        "# Training and evaluation functions\n",
        "def compute_accuracy(model, data_loader, device, is_cnn=False):\n",
        "    model.eval()\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data_loader:\n",
        "            if not is_cnn:\n",
        "                features = features.view(-1, 28*28)  # Flatten for MLP\n",
        "            features = features.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float() / num_examples * 100\n",
        "\n",
        "def train_model(model, train_loader, device, num_epochs, learning_rate, model_name, is_cnn=False):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    print(f\"Training {model_name}...\")\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "            if not is_cnn:\n",
        "                features = features.view(-1, 28*28)  # Flatten for MLP\n",
        "            features = features.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            logits = model(features)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if not batch_idx % 400:\n",
        "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} | Batch {batch_idx:03d}/{len(train_loader):03d} | Loss: {loss:.4f}')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            train_acc = compute_accuracy(model, train_loader, device, is_cnn)\n",
        "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} training accuracy: {train_acc:.2f}%')\n",
        "\n",
        "        print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
        "\n",
        "    print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "\n",
        "    # Test accuracy\n",
        "    test_acc = compute_accuracy(model, test_loader, device, is_cnn)\n",
        "    print(f'{model_name} test accuracy: {test_acc:.2f}%\\\\n')\n",
        "    return test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC7sPMzql_OO",
        "outputId": "7fa8113c-ea28-459c-ec33-8a8c6b49038e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MLP Baseline...\n",
            "Epoch: 001/010 | Batch 000/938 | Loss: 2.2971\n",
            "Epoch: 001/010 | Batch 400/938 | Loss: 0.1529\n",
            "Epoch: 001/010 | Batch 800/938 | Loss: 0.1094\n",
            "Epoch: 001/010 training accuracy: 96.01%\n",
            "Time elapsed: 0.28 min\n",
            "Epoch: 002/010 | Batch 000/938 | Loss: 0.1192\n",
            "Epoch: 002/010 | Batch 400/938 | Loss: 0.0593\n",
            "Epoch: 002/010 | Batch 800/938 | Loss: 0.0806\n",
            "Epoch: 002/010 training accuracy: 97.23%\n",
            "Time elapsed: 0.52 min\n",
            "Epoch: 003/010 | Batch 000/938 | Loss: 0.2192\n",
            "Epoch: 003/010 | Batch 400/938 | Loss: 0.0174\n",
            "Epoch: 003/010 | Batch 800/938 | Loss: 0.0418\n",
            "Epoch: 003/010 training accuracy: 98.11%\n",
            "Time elapsed: 0.77 min\n",
            "Epoch: 004/010 | Batch 000/938 | Loss: 0.0389\n",
            "Epoch: 004/010 | Batch 400/938 | Loss: 0.1433\n",
            "Epoch: 004/010 | Batch 800/938 | Loss: 0.1529\n",
            "Epoch: 004/010 training accuracy: 98.16%\n",
            "Time elapsed: 1.02 min\n",
            "Epoch: 005/010 | Batch 000/938 | Loss: 0.0858\n",
            "Epoch: 005/010 | Batch 400/938 | Loss: 0.1327\n",
            "Epoch: 005/010 | Batch 800/938 | Loss: 0.0151\n",
            "Epoch: 005/010 training accuracy: 98.30%\n",
            "Time elapsed: 1.29 min\n",
            "Epoch: 006/010 | Batch 000/938 | Loss: 0.0503\n",
            "Epoch: 006/010 | Batch 400/938 | Loss: 0.2504\n",
            "Epoch: 006/010 | Batch 800/938 | Loss: 0.0376\n",
            "Epoch: 006/010 training accuracy: 98.14%\n",
            "Time elapsed: 1.55 min\n",
            "Epoch: 007/010 | Batch 000/938 | Loss: 0.1096\n",
            "Epoch: 007/010 | Batch 400/938 | Loss: 0.1505\n",
            "Epoch: 007/010 | Batch 800/938 | Loss: 0.0065\n",
            "Epoch: 007/010 training accuracy: 98.79%\n",
            "Time elapsed: 1.79 min\n",
            "Epoch: 008/010 | Batch 000/938 | Loss: 0.0108\n",
            "Epoch: 008/010 | Batch 400/938 | Loss: 0.0848\n",
            "Epoch: 008/010 | Batch 800/938 | Loss: 0.0079\n",
            "Epoch: 008/010 training accuracy: 98.52%\n",
            "Time elapsed: 2.04 min\n",
            "Epoch: 009/010 | Batch 000/938 | Loss: 0.1655\n",
            "Epoch: 009/010 | Batch 400/938 | Loss: 0.0319\n",
            "Epoch: 009/010 | Batch 800/938 | Loss: 0.0050\n",
            "Epoch: 009/010 training accuracy: 98.72%\n",
            "Time elapsed: 2.29 min\n",
            "Epoch: 010/010 | Batch 000/938 | Loss: 0.0008\n",
            "Epoch: 010/010 | Batch 400/938 | Loss: 0.0072\n",
            "Epoch: 010/010 | Batch 800/938 | Loss: 0.0801\n",
            "Epoch: 010/010 training accuracy: 98.72%\n",
            "Time elapsed: 2.53 min\n",
            "Total Training Time: 2.53 min\n",
            "MLP Baseline test accuracy: 97.07%\\n\n",
            "Training CNN Baseline...\n",
            "Epoch: 001/010 | Batch 000/938 | Loss: 2.2959\n",
            "Epoch: 001/010 | Batch 400/938 | Loss: 0.1811\n",
            "Epoch: 001/010 | Batch 800/938 | Loss: 0.0699\n",
            "Epoch: 001/010 training accuracy: 98.27%\n",
            "Time elapsed: 0.27 min\n",
            "Epoch: 002/010 | Batch 000/938 | Loss: 0.0360\n",
            "Epoch: 002/010 | Batch 400/938 | Loss: 0.0108\n",
            "Epoch: 002/010 | Batch 800/938 | Loss: 0.0328\n",
            "Epoch: 002/010 training accuracy: 98.69%\n",
            "Time elapsed: 0.55 min\n",
            "Epoch: 003/010 | Batch 000/938 | Loss: 0.0029\n",
            "Epoch: 003/010 | Batch 400/938 | Loss: 0.0042\n",
            "Epoch: 003/010 | Batch 800/938 | Loss: 0.0219\n",
            "Epoch: 003/010 training accuracy: 99.09%\n",
            "Time elapsed: 0.82 min\n",
            "Epoch: 004/010 | Batch 000/938 | Loss: 0.0089\n",
            "Epoch: 004/010 | Batch 400/938 | Loss: 0.0512\n",
            "Epoch: 004/010 | Batch 800/938 | Loss: 0.0628\n",
            "Epoch: 004/010 training accuracy: 99.25%\n",
            "Time elapsed: 1.08 min\n",
            "Epoch: 005/010 | Batch 000/938 | Loss: 0.0041\n",
            "Epoch: 005/010 | Batch 400/938 | Loss: 0.0322\n",
            "Epoch: 005/010 | Batch 800/938 | Loss: 0.0365\n",
            "Epoch: 005/010 training accuracy: 99.18%\n",
            "Time elapsed: 1.36 min\n",
            "Epoch: 006/010 | Batch 000/938 | Loss: 0.0291\n",
            "Epoch: 006/010 | Batch 400/938 | Loss: 0.0033\n",
            "Epoch: 006/010 | Batch 800/938 | Loss: 0.0209\n",
            "Epoch: 006/010 training accuracy: 99.11%\n",
            "Time elapsed: 1.62 min\n",
            "Epoch: 007/010 | Batch 000/938 | Loss: 0.0279\n",
            "Epoch: 007/010 | Batch 400/938 | Loss: 0.0029\n",
            "Epoch: 007/010 | Batch 800/938 | Loss: 0.0047\n",
            "Epoch: 007/010 training accuracy: 99.57%\n",
            "Time elapsed: 1.89 min\n",
            "Epoch: 008/010 | Batch 000/938 | Loss: 0.0014\n",
            "Epoch: 008/010 | Batch 400/938 | Loss: 0.0367\n",
            "Epoch: 008/010 | Batch 800/938 | Loss: 0.0109\n",
            "Epoch: 008/010 training accuracy: 99.49%\n",
            "Time elapsed: 2.17 min\n",
            "Epoch: 009/010 | Batch 000/938 | Loss: 0.0002\n",
            "Epoch: 009/010 | Batch 400/938 | Loss: 0.0074\n",
            "Epoch: 009/010 | Batch 800/938 | Loss: 0.0211\n",
            "Epoch: 009/010 training accuracy: 99.55%\n",
            "Time elapsed: 2.43 min\n",
            "Epoch: 010/010 | Batch 000/938 | Loss: 0.0000\n",
            "Epoch: 010/010 | Batch 400/938 | Loss: 0.0127\n",
            "Epoch: 010/010 | Batch 800/938 | Loss: 0.0095\n",
            "Epoch: 010/010 training accuracy: 99.52%\n",
            "Time elapsed: 2.70 min\n",
            "Total Training Time: 2.70 min\n",
            "CNN Baseline test accuracy: 98.76%\\n\n",
            "Training Attention Baseline...\n",
            "Epoch: 001/010 | Batch 000/938 | Loss: 2.3384\n",
            "Epoch: 001/010 | Batch 400/938 | Loss: 1.0387\n",
            "Epoch: 001/010 | Batch 800/938 | Loss: 0.9900\n",
            "Epoch: 001/010 training accuracy: 74.22%\n",
            "Time elapsed: 0.28 min\n",
            "Epoch: 002/010 | Batch 000/938 | Loss: 0.9203\n",
            "Epoch: 002/010 | Batch 400/938 | Loss: 0.6606\n",
            "Epoch: 002/010 | Batch 800/938 | Loss: 0.6267\n",
            "Epoch: 002/010 training accuracy: 78.47%\n",
            "Time elapsed: 0.57 min\n",
            "Epoch: 003/010 | Batch 000/938 | Loss: 0.8945\n",
            "Epoch: 003/010 | Batch 400/938 | Loss: 0.7919\n",
            "Epoch: 003/010 | Batch 800/938 | Loss: 0.6568\n",
            "Epoch: 003/010 training accuracy: 76.60%\n",
            "Time elapsed: 0.86 min\n",
            "Epoch: 004/010 | Batch 000/938 | Loss: 0.6921\n",
            "Epoch: 004/010 | Batch 400/938 | Loss: 0.9100\n",
            "Epoch: 004/010 | Batch 800/938 | Loss: 0.9185\n",
            "Epoch: 004/010 training accuracy: 76.16%\n",
            "Time elapsed: 1.15 min\n",
            "Epoch: 005/010 | Batch 000/938 | Loss: 0.6516\n",
            "Epoch: 005/010 | Batch 400/938 | Loss: 0.9195\n",
            "Epoch: 005/010 | Batch 800/938 | Loss: 0.9858\n",
            "Epoch: 005/010 training accuracy: 79.58%\n",
            "Time elapsed: 1.45 min\n",
            "Epoch: 006/010 | Batch 000/938 | Loss: 0.6058\n",
            "Epoch: 006/010 | Batch 400/938 | Loss: 0.8309\n",
            "Epoch: 006/010 | Batch 800/938 | Loss: 0.6685\n",
            "Epoch: 006/010 training accuracy: 81.60%\n",
            "Time elapsed: 1.73 min\n",
            "Epoch: 007/010 | Batch 000/938 | Loss: 0.4330\n",
            "Epoch: 007/010 | Batch 400/938 | Loss: 0.5728\n",
            "Epoch: 007/010 | Batch 800/938 | Loss: 0.7439\n",
            "Epoch: 007/010 training accuracy: 78.33%\n",
            "Time elapsed: 2.03 min\n",
            "Epoch: 008/010 | Batch 000/938 | Loss: 0.5253\n",
            "Epoch: 008/010 | Batch 400/938 | Loss: 0.7373\n",
            "Epoch: 008/010 | Batch 800/938 | Loss: 0.5521\n",
            "Epoch: 008/010 training accuracy: 81.33%\n",
            "Time elapsed: 2.31 min\n",
            "Epoch: 009/010 | Batch 000/938 | Loss: 0.6536\n",
            "Epoch: 009/010 | Batch 400/938 | Loss: 0.6626\n",
            "Epoch: 009/010 | Batch 800/938 | Loss: 0.6974\n",
            "Epoch: 009/010 training accuracy: 81.14%\n",
            "Time elapsed: 2.61 min\n",
            "Epoch: 010/010 | Batch 000/938 | Loss: 0.3401\n",
            "Epoch: 010/010 | Batch 400/938 | Loss: 0.7391\n",
            "Epoch: 010/010 | Batch 800/938 | Loss: 0.5634\n",
            "Epoch: 010/010 training accuracy: 77.88%\n",
            "Time elapsed: 2.89 min\n",
            "Total Training Time: 2.89 min\n",
            "Attention Baseline test accuracy: 78.25%\\n\n"
          ]
        }
      ],
      "source": [
        "# Create and train baseline models\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# MLP\n",
        "mlp_model = MultilayerPerceptron()\n",
        "mlp_acc = train_model(mlp_model, train_loader, DEVICE, num_epochs, learning_rate, \"MLP Baseline\", is_cnn=False)\n",
        "\n",
        "# CNN\n",
        "cnn_model = SimpleCNN()\n",
        "cnn_acc = train_model(cnn_model, train_loader, DEVICE, num_epochs, learning_rate, \"CNN Baseline\", is_cnn=True)\n",
        "\n",
        "# Attention\n",
        "attn_model = SimpleAttentionModel()\n",
        "attn_acc = train_model(attn_model, train_loader, DEVICE, num_epochs, learning_rate, \"Attention Baseline\", is_cnn=True)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "HC6gH0kal_OO"
      },
      "source": [
        "## 7. Finetuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkTfntUvl_OO"
      },
      "outputs": [],
      "source": [
        "def apply_adaptations(model, adaptation_type, rank=4, alpha=8):\n",
        "    \"\"\"Apply LoRA or DoRA to model layers\"\"\"\n",
        "    model_adapted = copy.deepcopy(model)\n",
        "\n",
        "    if isinstance(model, MultilayerPerceptron):\n",
        "        # Apply to linear layers in MLP\n",
        "        if adaptation_type == 'lora':\n",
        "            model_adapted.layers[0] = LinearWithLoRA(model_adapted.layers[0], rank, alpha)\n",
        "            model_adapted.layers[2] = LinearWithLoRA(model_adapted.layers[2], rank, alpha)\n",
        "            model_adapted.layers[4] = LinearWithLoRA(model_adapted.layers[4], rank, alpha)\n",
        "        else:  # dora\n",
        "            model_adapted.layers[0] = LinearWithDoRA(model_adapted.layers[0], rank, alpha)\n",
        "            model_adapted.layers[2] = LinearWithDoRA(model_adapted.layers[2], rank, alpha)\n",
        "            model_adapted.layers[4] = LinearWithDoRA(model_adapted.layers[4], rank, alpha)\n",
        "\n",
        "    elif isinstance(model, SimpleCNN):\n",
        "        # Apply to classifier layers in CNN\n",
        "        if adaptation_type == 'lora':\n",
        "            model_adapted.classifier[1] = LinearWithLoRA(model_adapted.classifier[1], rank, alpha)\n",
        "            model_adapted.classifier[3] = LinearWithLoRA(model_adapted.classifier[3], rank, alpha)\n",
        "            model_adapted.classifier[5] = LinearWithLoRA(model_adapted.classifier[5], rank, alpha)\n",
        "        else:  # dora\n",
        "            model_adapted.classifier[1] = LinearWithDoRA(model_adapted.classifier[1], rank, alpha)\n",
        "            model_adapted.classifier[3] = LinearWithDoRA(model_adapted.classifier[3], rank, alpha)\n",
        "            model_adapted.classifier[5] = LinearWithDoRA(model_adapted.classifier[5], rank, alpha)\n",
        "\n",
        "    elif isinstance(model, SimpleAttentionModel):\n",
        "        # Apply to attention projections and classifier\n",
        "        if adaptation_type == 'lora':\n",
        "            model_adapted.attention.q_proj = LinearWithLoRA(model_adapted.attention.q_proj, rank*2, alpha*2)\n",
        "            model_adapted.attention.k_proj = LinearWithLoRA(model_adapted.attention.k_proj, rank*2, alpha*2)\n",
        "            model_adapted.attention.v_proj = LinearWithLoRA(model_adapted.attention.v_proj, rank*2, alpha*2)\n",
        "            model_adapted.attention.out_proj = LinearWithLoRA(model_adapted.attention.out_proj, rank*2, alpha*2)\n",
        "            model_adapted.patch_embed = LinearWithLoRA(model_adapted.patch_embed, rank, alpha)\n",
        "            model_adapted.classifier[1] = LinearWithLoRA(model_adapted.classifier[1], rank, alpha)\n",
        "            model_adapted.classifier[3] = LinearWithLoRA(model_adapted.classifier[3], rank, alpha)\n",
        "        else:  # dora\n",
        "            model_adapted.attention.q_proj = LinearWithDoRA(model_adapted.attention.q_proj, rank*2, alpha*2)\n",
        "            model_adapted.attention.k_proj = LinearWithDoRA(model_adapted.attention.k_proj, rank*2, alpha*2)\n",
        "            model_adapted.attention.v_proj = LinearWithDoRA(model_adapted.attention.v_proj, rank*2, alpha*2)\n",
        "            model_adapted.attention.out_proj = LinearWithDoRA(model_adapted.attention.out_proj, rank*2, alpha*2)\n",
        "            model_adapted.patch_embed = LinearWithDoRA(model_adapted.patch_embed, rank, alpha)\n",
        "            model_adapted.classifier[1] = LinearWithDoRA(model_adapted.classifier[1], rank, alpha)\n",
        "            model_adapted.classifier[3] = LinearWithDoRA(model_adapted.classifier[3], rank, alpha)\n",
        "\n",
        "    return model_adapted\n",
        "\n",
        "def freeze_base_parameters(model, adaptation_type):\n",
        "    \"\"\"Freeze all parameters except adaptation ones\"\"\"\n",
        "    for name, param in model.named_parameters():\n",
        "        if adaptation_type.lower() in ['lora', 'dora']:\n",
        "            if any(x in name for x in ['lora.A', 'lora.B', '.m']):\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "            param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Yh9nd-l_OO",
        "outputId": "f090a262-d062-4fb6-a447-4ce4a92163ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying adaptations and fine-tuning...\n",
            "\n",
            "Training MLP + LoRA...\n",
            "Epoch: 001/010 | Batch 000/938 | Loss: 0.0048\n",
            "Epoch: 001/010 | Batch 400/938 | Loss: 0.0304\n",
            "Epoch: 001/010 | Batch 800/938 | Loss: 0.2098\n",
            "Epoch: 001/010 training accuracy: 98.29%\n",
            "Time elapsed: 0.26 min\n",
            "Epoch: 002/010 | Batch 000/938 | Loss: 0.0198\n",
            "Epoch: 002/010 | Batch 400/938 | Loss: 0.0164\n",
            "Epoch: 002/010 | Batch 800/938 | Loss: 0.0015\n",
            "Epoch: 002/010 training accuracy: 98.86%\n",
            "Time elapsed: 0.53 min\n",
            "Epoch: 003/010 | Batch 000/938 | Loss: 0.0142\n",
            "Epoch: 003/010 | Batch 400/938 | Loss: 0.0454\n",
            "Epoch: 003/010 | Batch 800/938 | Loss: 0.0057\n",
            "Epoch: 003/010 training accuracy: 99.02%\n",
            "Time elapsed: 0.79 min\n",
            "Epoch: 004/010 | Batch 000/938 | Loss: 0.0592\n",
            "Epoch: 004/010 | Batch 400/938 | Loss: 0.0063\n",
            "Epoch: 004/010 | Batch 800/938 | Loss: 0.0117\n",
            "Epoch: 004/010 training accuracy: 99.11%\n",
            "Time elapsed: 1.05 min\n",
            "Epoch: 005/010 | Batch 000/938 | Loss: 0.0011\n",
            "Epoch: 005/010 | Batch 400/938 | Loss: 0.1442\n",
            "Epoch: 005/010 | Batch 800/938 | Loss: 0.0067\n",
            "Epoch: 005/010 training accuracy: 99.02%\n",
            "Time elapsed: 1.32 min\n",
            "Epoch: 006/010 | Batch 000/938 | Loss: 0.0019\n",
            "Epoch: 006/010 | Batch 400/938 | Loss: 0.0036\n",
            "Epoch: 006/010 | Batch 800/938 | Loss: 0.0007\n",
            "Epoch: 006/010 training accuracy: 98.50%\n",
            "Time elapsed: 1.58 min\n",
            "Epoch: 007/010 | Batch 000/938 | Loss: 0.0371\n",
            "Epoch: 007/010 | Batch 400/938 | Loss: 0.0983\n",
            "Epoch: 007/010 | Batch 800/938 | Loss: 0.0314\n",
            "Epoch: 007/010 training accuracy: 98.72%\n",
            "Time elapsed: 1.84 min\n",
            "Epoch: 008/010 | Batch 000/938 | Loss: 0.1341\n",
            "Epoch: 008/010 | Batch 400/938 | Loss: 0.0029\n",
            "Epoch: 008/010 | Batch 800/938 | Loss: 0.0140\n",
            "Epoch: 008/010 training accuracy: 99.01%\n",
            "Time elapsed: 2.12 min\n",
            "Epoch: 009/010 | Batch 000/938 | Loss: 0.1533\n",
            "Epoch: 009/010 | Batch 400/938 | Loss: 0.0539\n",
            "Epoch: 009/010 | Batch 800/938 | Loss: 0.0181\n",
            "Epoch: 009/010 training accuracy: 98.83%\n",
            "Time elapsed: 2.38 min\n",
            "Epoch: 010/010 | Batch 000/938 | Loss: 0.0628\n",
            "Epoch: 010/010 | Batch 400/938 | Loss: 0.0054\n",
            "Epoch: 010/010 | Batch 800/938 | Loss: 0.0003\n",
            "Epoch: 010/010 training accuracy: 98.97%\n",
            "Time elapsed: 2.64 min\n",
            "Total Training Time: 2.64 min\n",
            "MLP + LoRA test accuracy: 97.32%\\n\n",
            "Training MLP + DoRA...\n",
            "Epoch: 001/010 | Batch 000/938 | Loss: 0.0013\n",
            "Epoch: 001/010 | Batch 400/938 | Loss: 0.0063\n",
            "Epoch: 001/010 | Batch 800/938 | Loss: 0.0041\n",
            "Epoch: 001/010 training accuracy: 98.88%\n",
            "Time elapsed: 0.29 min\n",
            "Epoch: 002/010 | Batch 000/938 | Loss: 0.0057\n",
            "Epoch: 002/010 | Batch 400/938 | Loss: 0.0083\n",
            "Epoch: 002/010 | Batch 800/938 | Loss: 0.0283\n",
            "Epoch: 002/010 training accuracy: 98.88%\n",
            "Time elapsed: 0.58 min\n",
            "Epoch: 003/010 | Batch 000/938 | Loss: 0.0275\n",
            "Epoch: 003/010 | Batch 400/938 | Loss: 0.0051\n",
            "Epoch: 003/010 | Batch 800/938 | Loss: 0.0157\n",
            "Epoch: 003/010 training accuracy: 98.88%\n",
            "Time elapsed: 0.87 min\n",
            "Epoch: 004/010 | Batch 000/938 | Loss: 0.0077\n",
            "Epoch: 004/010 | Batch 400/938 | Loss: 0.0037\n",
            "Epoch: 004/010 | Batch 800/938 | Loss: 0.0024\n",
            "Epoch: 004/010 training accuracy: 99.27%\n",
            "Time elapsed: 1.15 min\n",
            "Epoch: 005/010 | Batch 000/938 | Loss: 0.0536\n",
            "Epoch: 005/010 | Batch 400/938 | Loss: 0.0133\n",
            "Epoch: 005/010 | Batch 800/938 | Loss: 0.0420\n",
            "Epoch: 005/010 training accuracy: 99.33%\n",
            "Time elapsed: 1.44 min\n",
            "Epoch: 006/010 | Batch 000/938 | Loss: 0.0160\n",
            "Epoch: 006/010 | Batch 400/938 | Loss: 0.0135\n",
            "Epoch: 006/010 | Batch 800/938 | Loss: 0.0079\n",
            "Epoch: 006/010 training accuracy: 99.24%\n",
            "Time elapsed: 1.73 min\n",
            "Epoch: 007/010 | Batch 000/938 | Loss: 0.0019\n",
            "Epoch: 007/010 | Batch 400/938 | Loss: 0.0327\n",
            "Epoch: 007/010 | Batch 800/938 | Loss: 0.0092\n",
            "Epoch: 007/010 training accuracy: 99.17%\n",
            "Time elapsed: 2.01 min\n",
            "Epoch: 008/010 | Batch 000/938 | Loss: 0.0017\n",
            "Epoch: 008/010 | Batch 400/938 | Loss: 0.0624\n",
            "Epoch: 008/010 | Batch 800/938 | Loss: 0.0205\n",
            "Epoch: 008/010 training accuracy: 99.10%\n",
            "Time elapsed: 2.30 min\n",
            "Epoch: 009/010 | Batch 000/938 | Loss: 0.0344\n",
            "Epoch: 009/010 | Batch 400/938 | Loss: 0.1063\n",
            "Epoch: 009/010 | Batch 800/938 | Loss: 0.0268\n",
            "Epoch: 009/010 training accuracy: 99.45%\n",
            "Time elapsed: 2.58 min\n",
            "Epoch: 010/010 | Batch 000/938 | Loss: 0.0204\n",
            "Epoch: 010/010 | Batch 400/938 | Loss: 0.0235\n",
            "Epoch: 010/010 | Batch 800/938 | Loss: 0.1286\n",
            "Epoch: 010/010 training accuracy: 99.36%\n",
            "Time elapsed: 2.87 min\n",
            "Total Training Time: 2.87 min\n",
            "MLP + DoRA test accuracy: 97.66%\\n\n",
            "Training CNN + LoRA...\n",
            "Epoch: 001/010 | Batch 000/938 | Loss: 0.0024\n",
            "Epoch: 001/010 | Batch 400/938 | Loss: 0.0083\n",
            "Epoch: 001/010 | Batch 800/938 | Loss: 0.0011\n",
            "Epoch: 001/010 training accuracy: 99.50%\n",
            "Time elapsed: 0.27 min\n",
            "Epoch: 002/010 | Batch 000/938 | Loss: 0.1209\n",
            "Epoch: 002/010 | Batch 400/938 | Loss: 0.0013\n",
            "Epoch: 002/010 | Batch 800/938 | Loss: 0.0719\n",
            "Epoch: 002/010 training accuracy: 99.57%\n",
            "Time elapsed: 0.56 min\n",
            "Epoch: 003/010 | Batch 000/938 | Loss: 0.0010\n",
            "Epoch: 003/010 | Batch 400/938 | Loss: 0.0212\n",
            "Epoch: 003/010 | Batch 800/938 | Loss: 0.0041\n",
            "Epoch: 003/010 training accuracy: 99.56%\n",
            "Time elapsed: 0.83 min\n",
            "Epoch: 004/010 | Batch 000/938 | Loss: 0.0265\n",
            "Epoch: 004/010 | Batch 400/938 | Loss: 0.0005\n",
            "Epoch: 004/010 | Batch 800/938 | Loss: 0.0297\n",
            "Epoch: 004/010 training accuracy: 99.62%\n",
            "Time elapsed: 1.11 min\n",
            "Epoch: 005/010 | Batch 000/938 | Loss: 0.0016\n",
            "Epoch: 005/010 | Batch 400/938 | Loss: 0.1822\n",
            "Epoch: 005/010 | Batch 800/938 | Loss: 0.0811\n",
            "Epoch: 005/010 training accuracy: 99.62%\n",
            "Time elapsed: 1.39 min\n",
            "Epoch: 006/010 | Batch 000/938 | Loss: 0.0005\n",
            "Epoch: 006/010 | Batch 400/938 | Loss: 0.0003\n",
            "Epoch: 006/010 | Batch 800/938 | Loss: 0.0010\n",
            "Epoch: 006/010 training accuracy: 99.63%\n",
            "Time elapsed: 1.67 min\n",
            "Epoch: 007/010 | Batch 000/938 | Loss: 0.0026\n",
            "Epoch: 007/010 | Batch 400/938 | Loss: 0.0011\n",
            "Epoch: 007/010 | Batch 800/938 | Loss: 0.0022\n",
            "Epoch: 007/010 training accuracy: 99.50%\n",
            "Time elapsed: 1.95 min\n",
            "Epoch: 008/010 | Batch 000/938 | Loss: 0.0174\n",
            "Epoch: 008/010 | Batch 400/938 | Loss: 0.0006\n",
            "Epoch: 008/010 | Batch 800/938 | Loss: 0.0291\n",
            "Epoch: 008/010 training accuracy: 99.75%\n",
            "Time elapsed: 2.23 min\n",
            "Epoch: 009/010 | Batch 000/938 | Loss: 0.0003\n",
            "Epoch: 009/010 | Batch 400/938 | Loss: 0.0045\n",
            "Epoch: 009/010 | Batch 800/938 | Loss: 0.0063\n",
            "Epoch: 009/010 training accuracy: 99.62%\n",
            "Time elapsed: 2.50 min\n",
            "Epoch: 010/010 | Batch 000/938 | Loss: 0.0187\n",
            "Epoch: 010/010 | Batch 400/938 | Loss: 0.0094\n",
            "Epoch: 010/010 | Batch 800/938 | Loss: 0.0001\n",
            "Epoch: 010/010 training accuracy: 99.33%\n",
            "Time elapsed: 2.78 min\n",
            "Total Training Time: 2.78 min\n",
            "CNN + LoRA test accuracy: 98.55%\\n\n",
            "Training CNN + DoRA...\n",
            "Epoch: 001/010 | Batch 000/938 | Loss: 0.0001\n",
            "Epoch: 001/010 | Batch 400/938 | Loss: 0.0460\n",
            "Epoch: 001/010 | Batch 800/938 | Loss: 0.0320\n",
            "Epoch: 001/010 training accuracy: 99.54%\n",
            "Time elapsed: 0.29 min\n",
            "Epoch: 002/010 | Batch 000/938 | Loss: 0.0216\n",
            "Epoch: 002/010 | Batch 400/938 | Loss: 0.0847\n",
            "Epoch: 002/010 | Batch 800/938 | Loss: 0.0103\n",
            "Epoch: 002/010 training accuracy: 99.67%\n",
            "Time elapsed: 0.60 min\n",
            "Epoch: 003/010 | Batch 000/938 | Loss: 0.0152\n",
            "Epoch: 003/010 | Batch 400/938 | Loss: 0.0336\n",
            "Epoch: 003/010 | Batch 800/938 | Loss: 0.0219\n",
            "Epoch: 003/010 training accuracy: 99.68%\n",
            "Time elapsed: 0.89 min\n",
            "Epoch: 004/010 | Batch 000/938 | Loss: 0.0005\n",
            "Epoch: 004/010 | Batch 400/938 | Loss: 0.0010\n",
            "Epoch: 004/010 | Batch 800/938 | Loss: 0.0013\n",
            "Epoch: 004/010 training accuracy: 99.59%\n",
            "Time elapsed: 1.19 min\n",
            "Epoch: 005/010 | Batch 000/938 | Loss: 0.0046\n",
            "Epoch: 005/010 | Batch 400/938 | Loss: 0.0032\n",
            "Epoch: 005/010 | Batch 800/938 | Loss: 0.0560\n",
            "Epoch: 005/010 training accuracy: 99.75%\n",
            "Time elapsed: 1.48 min\n",
            "Epoch: 006/010 | Batch 000/938 | Loss: 0.0012\n",
            "Epoch: 006/010 | Batch 400/938 | Loss: 0.0001\n",
            "Epoch: 006/010 | Batch 800/938 | Loss: 0.0015\n",
            "Epoch: 006/010 training accuracy: 99.81%\n",
            "Time elapsed: 1.79 min\n",
            "Epoch: 007/010 | Batch 000/938 | Loss: 0.0022\n",
            "Epoch: 007/010 | Batch 400/938 | Loss: 0.0000\n",
            "Epoch: 007/010 | Batch 800/938 | Loss: 0.0576\n",
            "Epoch: 007/010 training accuracy: 99.58%\n",
            "Time elapsed: 2.08 min\n",
            "Epoch: 008/010 | Batch 000/938 | Loss: 0.0049\n",
            "Epoch: 008/010 | Batch 400/938 | Loss: 0.0001\n",
            "Epoch: 008/010 | Batch 800/938 | Loss: 0.0037\n",
            "Epoch: 008/010 training accuracy: 99.75%\n",
            "Time elapsed: 2.38 min\n",
            "Epoch: 009/010 | Batch 000/938 | Loss: 0.0005\n",
            "Epoch: 009/010 | Batch 400/938 | Loss: 0.0007\n",
            "Epoch: 009/010 | Batch 800/938 | Loss: 0.0002\n",
            "Epoch: 009/010 training accuracy: 99.64%\n",
            "Time elapsed: 2.67 min\n",
            "Epoch: 010/010 | Batch 000/938 | Loss: 0.0013\n",
            "Epoch: 010/010 | Batch 400/938 | Loss: 0.0061\n",
            "Epoch: 010/010 | Batch 800/938 | Loss: 0.0881\n",
            "Epoch: 010/010 training accuracy: 99.71%\n",
            "Time elapsed: 2.97 min\n",
            "Total Training Time: 2.97 min\n",
            "CNN + DoRA test accuracy: 98.93%\\n\n",
            "Training Attention + LoRA...\n",
            "Epoch: 001/010 | Batch 000/938 | Loss: 0.7448\n",
            "Epoch: 001/010 | Batch 400/938 | Loss: 1.0861\n",
            "Epoch: 001/010 | Batch 800/938 | Loss: 1.5548\n",
            "Epoch: 001/010 training accuracy: 54.37%\n",
            "Time elapsed: 0.31 min\n",
            "Epoch: 002/010 | Batch 000/938 | Loss: 1.2957\n",
            "Epoch: 002/010 | Batch 400/938 | Loss: 1.6242\n",
            "Epoch: 002/010 | Batch 800/938 | Loss: 1.7649\n",
            "Epoch: 002/010 training accuracy: 41.96%\n",
            "Time elapsed: 0.63 min\n",
            "Epoch: 003/010 | Batch 000/938 | Loss: 1.6084\n",
            "Epoch: 003/010 | Batch 400/938 | Loss: 1.7136\n",
            "Epoch: 003/010 | Batch 800/938 | Loss: 1.8759\n",
            "Epoch: 003/010 training accuracy: 35.03%\n",
            "Time elapsed: 0.95 min\n",
            "Epoch: 004/010 | Batch 000/938 | Loss: 1.8122\n",
            "Epoch: 004/010 | Batch 400/938 | Loss: 1.9368\n",
            "Epoch: 004/010 | Batch 800/938 | Loss: 1.6076\n",
            "Epoch: 004/010 training accuracy: 37.45%\n",
            "Time elapsed: 1.26 min\n",
            "Epoch: 005/010 | Batch 000/938 | Loss: 1.9109\n",
            "Epoch: 005/010 | Batch 400/938 | Loss: 1.8281\n",
            "Epoch: 005/010 | Batch 800/938 | Loss: 1.7623\n",
            "Epoch: 005/010 training accuracy: 37.47%\n",
            "Time elapsed: 1.58 min\n",
            "Epoch: 006/010 | Batch 000/938 | Loss: 1.5133\n",
            "Epoch: 006/010 | Batch 400/938 | Loss: 1.9082\n",
            "Epoch: 006/010 | Batch 800/938 | Loss: 1.9112\n",
            "Epoch: 006/010 training accuracy: 38.07%\n",
            "Time elapsed: 1.90 min\n",
            "Epoch: 007/010 | Batch 000/938 | Loss: 1.5958\n",
            "Epoch: 007/010 | Batch 400/938 | Loss: 1.5939\n",
            "Epoch: 007/010 | Batch 800/938 | Loss: 1.6697\n",
            "Epoch: 007/010 training accuracy: 40.48%\n",
            "Time elapsed: 2.22 min\n",
            "Epoch: 008/010 | Batch 000/938 | Loss: 1.6160\n",
            "Epoch: 008/010 | Batch 400/938 | Loss: 1.8864\n",
            "Epoch: 008/010 | Batch 800/938 | Loss: 2.0231\n",
            "Epoch: 008/010 training accuracy: 33.06%\n",
            "Time elapsed: 2.53 min\n",
            "Epoch: 009/010 | Batch 000/938 | Loss: 1.8135\n",
            "Epoch: 009/010 | Batch 400/938 | Loss: 1.8335\n",
            "Epoch: 009/010 | Batch 800/938 | Loss: 1.8455\n",
            "Epoch: 009/010 training accuracy: 37.80%\n",
            "Time elapsed: 2.85 min\n",
            "Epoch: 010/010 | Batch 000/938 | Loss: 1.8610\n",
            "Epoch: 010/010 | Batch 400/938 | Loss: 1.7987\n",
            "Epoch: 010/010 | Batch 800/938 | Loss: 1.7101\n",
            "Epoch: 010/010 training accuracy: 38.58%\n",
            "Time elapsed: 3.18 min\n",
            "Total Training Time: 3.18 min\n",
            "Attention + LoRA test accuracy: 38.91%\\n\n",
            "Training Attention + DoRA...\n",
            "Epoch: 001/010 | Batch 000/938 | Loss: 0.7880\n",
            "Epoch: 001/010 | Batch 400/938 | Loss: 0.8667\n",
            "Epoch: 001/010 | Batch 800/938 | Loss: 0.9844\n",
            "Epoch: 001/010 training accuracy: 75.81%\n",
            "Time elapsed: 0.36 min\n",
            "Epoch: 002/010 | Batch 000/938 | Loss: 0.7257\n",
            "Epoch: 002/010 | Batch 400/938 | Loss: 0.8913\n",
            "Epoch: 002/010 | Batch 800/938 | Loss: 0.5765\n",
            "Epoch: 002/010 training accuracy: 76.93%\n",
            "Time elapsed: 0.72 min\n",
            "Epoch: 003/010 | Batch 000/938 | Loss: 0.6965\n",
            "Epoch: 003/010 | Batch 400/938 | Loss: 0.5630\n",
            "Epoch: 003/010 | Batch 800/938 | Loss: 0.4886\n",
            "Epoch: 003/010 training accuracy: 78.91%\n",
            "Time elapsed: 1.08 min\n",
            "Epoch: 004/010 | Batch 000/938 | Loss: 0.4598\n",
            "Epoch: 004/010 | Batch 400/938 | Loss: 0.6414\n",
            "Epoch: 004/010 | Batch 800/938 | Loss: 0.8561\n",
            "Epoch: 004/010 training accuracy: 78.69%\n",
            "Time elapsed: 1.45 min\n",
            "Epoch: 005/010 | Batch 000/938 | Loss: 0.7455\n",
            "Epoch: 005/010 | Batch 400/938 | Loss: 0.4555\n",
            "Epoch: 005/010 | Batch 800/938 | Loss: 0.5515\n",
            "Epoch: 005/010 training accuracy: 76.11%\n",
            "Time elapsed: 1.81 min\n",
            "Epoch: 006/010 | Batch 000/938 | Loss: 0.6790\n",
            "Epoch: 006/010 | Batch 400/938 | Loss: 0.9092\n",
            "Epoch: 006/010 | Batch 800/938 | Loss: 0.7596\n",
            "Epoch: 006/010 training accuracy: 74.01%\n",
            "Time elapsed: 2.17 min\n",
            "Epoch: 007/010 | Batch 000/938 | Loss: 0.6763\n",
            "Epoch: 007/010 | Batch 400/938 | Loss: 0.6025\n",
            "Epoch: 007/010 | Batch 800/938 | Loss: 0.9500\n",
            "Epoch: 007/010 training accuracy: 76.18%\n",
            "Time elapsed: 2.53 min\n",
            "Epoch: 008/010 | Batch 000/938 | Loss: 0.7705\n",
            "Epoch: 008/010 | Batch 400/938 | Loss: 0.7187\n",
            "Epoch: 008/010 | Batch 800/938 | Loss: 0.5874\n",
            "Epoch: 008/010 training accuracy: 78.43%\n",
            "Time elapsed: 2.89 min\n",
            "Epoch: 009/010 | Batch 000/938 | Loss: 0.4524\n",
            "Epoch: 009/010 | Batch 400/938 | Loss: 0.5201\n",
            "Epoch: 009/010 | Batch 800/938 | Loss: 0.5979\n",
            "Epoch: 009/010 training accuracy: 80.10%\n",
            "Time elapsed: 3.25 min\n",
            "Epoch: 010/010 | Batch 000/938 | Loss: 0.4693\n",
            "Epoch: 010/010 | Batch 400/938 | Loss: 0.6536\n",
            "Epoch: 010/010 | Batch 800/938 | Loss: 0.5569\n",
            "Epoch: 010/010 training accuracy: 78.47%\n",
            "Time elapsed: 3.61 min\n",
            "Total Training Time: 3.61 min\n",
            "Attention + DoRA test accuracy: 78.51%\\n\n"
          ]
        }
      ],
      "source": [
        "# Apply LoRA and DoRA to all models\n",
        "print(\"Applying adaptations and fine-tuning...\\n\")\n",
        "\n",
        "results = {}\n",
        "\n",
        "# MLP with LoRA/DoRA\n",
        "mlp_lora = apply_adaptations(mlp_model, 'lora', rank=4, alpha=8)\n",
        "mlp_dora = apply_adaptations(mlp_model, 'dora', rank=4, alpha=8)\n",
        "\n",
        "freeze_base_parameters(mlp_lora, 'lora')\n",
        "freeze_base_parameters(mlp_dora, 'dora')\n",
        "\n",
        "results['mlp_lora'] = train_model(mlp_lora, train_loader, DEVICE, num_epochs, learning_rate, \"MLP + LoRA\", is_cnn=False)\n",
        "results['mlp_dora'] = train_model(mlp_dora, train_loader, DEVICE, num_epochs, learning_rate, \"MLP + DoRA\", is_cnn=False)\n",
        "\n",
        "# CNN with LoRA/DoRA\n",
        "cnn_lora = apply_adaptations(cnn_model, 'lora', rank=4, alpha=8)\n",
        "cnn_dora = apply_adaptations(cnn_model, 'dora', rank=4, alpha=8)\n",
        "\n",
        "freeze_base_parameters(cnn_lora, 'lora')\n",
        "freeze_base_parameters(cnn_dora, 'dora')\n",
        "\n",
        "results['cnn_lora'] = train_model(cnn_lora, train_loader, DEVICE, num_epochs, learning_rate, \"CNN + LoRA\", is_cnn=True)\n",
        "results['cnn_dora'] = train_model(cnn_dora, train_loader, DEVICE, num_epochs, learning_rate, \"CNN + DoRA\", is_cnn=True)\n",
        "\n",
        "# Attention with LoRA/DoRA\n",
        "attn_lora = apply_adaptations(attn_model, 'lora', rank=4, alpha=8)\n",
        "attn_dora = apply_adaptations(attn_model, 'dora', rank=4, alpha=8)\n",
        "\n",
        "freeze_base_parameters(attn_lora, 'lora')\n",
        "freeze_base_parameters(attn_dora, 'dora')\n",
        "\n",
        "results['attn_lora'] = train_model(attn_lora, train_loader, DEVICE, num_epochs, learning_rate, \"Attention + LoRA\", is_cnn=True)\n",
        "results['attn_dora'] = train_model(attn_dora, train_loader, DEVICE, num_epochs, learning_rate, \"Attention + DoRA\", is_cnn=True)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "joUwdU8Xl_OO"
      },
      "source": [
        "## 8. Performance Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXZdk7WXl_OO",
        "outputId": "e2b84fd1-83a8-4362-836a-21a1bc8ddd49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Final Results Summary ===\n",
            "\n",
            "📊 PERFORMANCE COMPARISON:\n",
            "\n",
            "MLP Results:\n",
            "  Baseline:     97.07%\n",
            "  + LoRA:       97.32%\n",
            "  + DoRA:       97.66%\n",
            "\n",
            "CNN Results:\n",
            "  Baseline:     98.76%\n",
            "  + LoRA:       98.55%\n",
            "  + DoRA:       98.93%\n",
            "\n",
            "Attention Results:\n",
            "  Baseline:     78.25%\n",
            "  + LoRA:       38.91%\n",
            "  + DoRA:       78.51%\n",
            "\n",
            "🔧 PARAMETER COUNTS:\n",
            "\n",
            "MLP:\n",
            "  Baseline:     136,074 parameters\n",
            "  + LoRA:       6,248 trainable parameters\n",
            "  + DoRA:       7,416 trainable parameters\n",
            "\n",
            "CNN:\n",
            "  Baseline:     429,258 parameters\n",
            "  + LoRA:       14,120 trainable parameters\n",
            "  + DoRA:       17,448 trainable parameters\n",
            "\n",
            "Attention:\n",
            "  Baseline:     83,658 parameters\n",
            "  + LoRA:       9,832 trainable parameters\n",
            "  + DoRA:       10,552 trainable parameters\n",
            "\n",
            "✅ SUMMARY:\n",
            "DoRA consistently shows competitive or superior performance to LoRA\n",
            "across all three architectures (MLP, CNN, Attention) while maintaining\n",
            "similar parameter efficiency through low-rank adaptation.\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"=== Final Results Summary ===\")\n",
        "print()\n",
        "\n",
        "print(\"📊 PERFORMANCE COMPARISON:\")\n",
        "print()\n",
        "\n",
        "print(\"MLP Results:\")\n",
        "print(f\"  Baseline:     {mlp_acc:.2f}%\")\n",
        "print(f\"  + LoRA:       {results['mlp_lora']:.2f}%\")\n",
        "print(f\"  + DoRA:       {results['mlp_dora']:.2f}%\")\n",
        "print()\n",
        "\n",
        "print(\"CNN Results:\")\n",
        "print(f\"  Baseline:     {cnn_acc:.2f}%\")\n",
        "print(f\"  + LoRA:       {results['cnn_lora']:.2f}%\")\n",
        "print(f\"  + DoRA:       {results['cnn_dora']:.2f}%\")\n",
        "print()\n",
        "\n",
        "print(\"Attention Results:\")\n",
        "print(f\"  Baseline:     {attn_acc:.2f}%\")\n",
        "print(f\"  + LoRA:       {results['attn_lora']:.2f}%\")\n",
        "print(f\"  + DoRA:       {results['attn_dora']:.2f}%\")\n",
        "print()\n",
        "\n",
        "print(\"🔧 PARAMETER COUNTS:\")\n",
        "print()\n",
        "print(\"MLP:\")\n",
        "print(f\"  Baseline:     {count_parameters(mlp_model):,} parameters\")\n",
        "print(f\"  + LoRA:       {count_parameters(mlp_lora):,} trainable parameters\")\n",
        "print(f\"  + DoRA:       {count_parameters(mlp_dora):,} trainable parameters\")\n",
        "print()\n",
        "\n",
        "print(\"CNN:\")\n",
        "print(f\"  Baseline:     {count_parameters(cnn_model):,} parameters\")\n",
        "print(f\"  + LoRA:       {count_parameters(cnn_lora):,} trainable parameters\")\n",
        "print(f\"  + DoRA:       {count_parameters(cnn_dora):,} trainable parameters\")\n",
        "print()\n",
        "\n",
        "print(\"Attention:\")\n",
        "print(f\"  Baseline:     {count_parameters(attn_model):,} parameters\")\n",
        "print(f\"  + LoRA:       {count_parameters(attn_lora):,} trainable parameters\")\n",
        "print(f\"  + DoRA:       {count_parameters(attn_dora):,} trainable parameters\")\n",
        "print()\n",
        "\n",
        "print(\"✅ SUMMARY:\")\n",
        "print(\"DoRA consistently shows competitive or superior performance to LoRA\")\n",
        "print(\"across all three architectures (MLP, CNN, Attention) while maintaining\")\n",
        "print(\"similar parameter efficiency through low-rank adaptation.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3q2EdV4Znqw1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}